{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import torch as tr\n",
    "\n",
    "TrainConfig = namedtuple(\n",
    "    'TrainConfig',\n",
    "    'n_step_tboard_log '\n",
    "    'n_step_console_log '\n",
    "    'n_step_validation '\n",
    "    'n_step_save_params '\n",
    "    'n_step_visualize'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    use_gpu = tr.cuda.is_available()\n",
    "\n",
    "    dtype = tr.float32\n",
    "\n",
    "    base_port = 8001\n",
    "\n",
    "    default_train_config = TrainConfig(\n",
    "        n_step_tboard_log=50,\n",
    "        n_step_console_log=-1,\n",
    "        n_step_validation=100,\n",
    "        n_step_save_params=1000,\n",
    "        n_step_visualize=500\n",
    "    )\n",
    "    \n",
    "x = Config()\n",
    "x.default_train_config.n_step_console_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_output(use_gpu=Config.use_gpu):\n",
    "    def outer(f):\n",
    "        def inner(*args,**kwargs):\n",
    "            ret = f(*args,**kwargs)\n",
    "            return tr.tensor(ret)\n",
    "        return inner\n",
    "    return outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tensor_output(use_gpu=Config.use_gpu)\n",
    "def numpy(val=10):\n",
    "    return np.random.rand(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5654], dtype=torch.float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tr.tensor([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 4, 5, 2, 9, 1, 3, 6, 0, 8])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as tr\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn import functional as F\n",
    "from base.hyperparams import Hyperparams\n",
    "from base.model import BaseModel\n",
    "from torch import nn\n",
    "from exp_context import ExperimentContext\n",
    "from utils.commons import NLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpConvBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, bn=True, kernel_size=5, stride=2, output_padding=(0, 0), padding=(2, 2)):\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, output_padding=output_padding,\n",
    "                               padding=padding)]\n",
    "        if bn:\n",
    "            layers.append(nn.BatchNorm2d(out_channels, 0.8))\n",
    "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        super(UpConvBlock, self).__init__(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tconv1 = UpConvBlock(in_channels=32, out_channels=16, kernel_size=5, stride=2, output_padding=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpConvBlock(\n",
       "  (0): ConvTranspose2d(32, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "  (1): BatchNorm2d(16, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tconv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.factory import DataLoaderFactory\n",
    "\n",
    "import numpy as np\n",
    "import os, argparse, json, logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp_context import ExperimentContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args_str = '-hp hyperparameters/digit_mnist.py -d all -en awa -t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-en', '--exp_name'], dest='exp_name', nargs=None, const=None, default=None, type=None, choices=None, help='experiment name. if not provided, it is taken from Hyperparams', metavar=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Argument Parsing\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('-g', '--gpu', default=0, help='index of the gpu to be used. default: 0')\n",
    "parser.add_argument('-t', '--tensorboard', default=False, const=True, nargs='?', help='Start Tensorboard with the experiment')\n",
    "parser.add_argument('-r', '--resume', nargs='?', const=True, default=False,\n",
    "                    help='if present, the training resumes from the latest step, '\n",
    "                         'for custom step number, provide it as argument value')\n",
    "parser.add_argument('-d', '--delete', nargs='+', default=[], choices=['logs', 'weights', 'results', 'all'],\n",
    "                    help='delete the entities')\n",
    "parser.add_argument('-w', '--weights', nargs='?', default='iter', choices=['iter', 'best_gen', 'best_pred'],\n",
    "                    help='weight type to load if resume flag is provided. default: iter')\n",
    "parser.add_argument('-hp', '--hyperparams', required=True, help='hyperparam class to use from HyperparamFactory')\n",
    "parser.add_argument('-en', '--exp_name', default=None, help='experiment name. if not provided, it is taken from Hyperparams')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(default_args_str.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"gpu\": 0,\n",
      "  \"tensorboard\": true,\n",
      "  \"resume\": false,\n",
      "  \"delete\": [\n",
      "    \"all\"\n",
      "  ],\n",
      "  \"weights\": \"iter\",\n",
      "  \"hyperparams\": \"hyperparameters/digit_mnist.py\",\n",
      "  \"exp_name\": \"awa\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(args.__dict__, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading HP from file\n",
      "importing hyperparams hyperparameters.digit_mnist\n"
     ]
    }
   ],
   "source": [
    "resume_flag = args.resume is not False\n",
    "ExperimentContext.set_context(args.hyperparams, args.exp_name)\n",
    "H = ExperimentContext.Hyperparams  # type: Hyperparams\n",
    "exp_name = ExperimentContext.exp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "LOG_FORMAT = \"[{}: %(filename)s: %(lineno)3s] %(levelname)s: %(funcName)s(): %(message)s\".format(ExperimentContext.exp_name)\n",
    "logging.basicConfig(level=logging.INFO, format=LOG_FORMAT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Clear Logs and Results based on the argument flags ####\n",
    "from paths import Paths\n",
    "from utils import bash_utils, model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[awa: <ipython-input-15-b5d7d7b2dfb5>:   2] WARNING: <module>(): Deleting Logs...\n",
      "[awa: <ipython-input-15-b5d7d7b2dfb5>:   7] WARNING: <module>(): Deleting all results in ../experiments/awa/results...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if 'all' in args.delete or 'logs' in args.delete or resume_flag is False:\n",
    "    logger.warning('Deleting Logs...')\n",
    "    bash_utils.delete_recursive(Paths.logs_base_dir)\n",
    "    print('')\n",
    "\n",
    "if 'all' in args.delete or 'results' in args.delete:\n",
    "    logger.warning('Deleting all results in {}...'.format(Paths.results_base_dir))\n",
    "    bash_utils.delete_recursive(Paths.results_base_dir)\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dirs created\n"
     ]
    }
   ],
   "source": [
    "##### Create required directories\n",
    "model_utils.setup_dirs()\n",
    "print('dirs created')\n",
    "###################\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "dl = DataLoaderFactory.get_dataloader(H.dataloader, H.batch_size, H.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dataloaders.mnist.MnistDataLoader at 0x1247ced10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base.dataloader as DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DL.get_z_dist(1,'normal',bounds=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import base.dataloader as DL\n",
    "from models.mnist.gan import ImgGAN\n",
    "from dataloaders.mnist import MnistDataLoader\n",
    "mdl = MnistDataLoader()\n",
    "train_data, test_data, train_labels, test_labels = mdl.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "with tqdm(total = epochs) as pbar:\n",
    "    for ep in range(epochs):\n",
    "        print(ep)\n",
    "        # add code from here\n",
    "        noise = DL.get_z_dist(H.batch_size, 'normal', bounds=1)\n",
    "        if flag == 0:\n",
    "            gen_loss = ImgGAN.gen_adv_loss_x(noise)\n",
    "            gen_loss.backward()\n",
    "            ImgGAN.opt['generator'].step()\n",
    "            if(ep%20 == 0)\n",
    "                flag = 1            \n",
    "        else:\n",
    "            for i_batch, x in enumerate(train_data):\n",
    "                disc_loss = ImgGAN.disc_adv_loss_x(x, noise)\n",
    "                disc_loss.backward()\n",
    "                ImgGAN.opt['disc_x'].step()\n",
    "            count=+1\n",
    "            if(count == 20):\n",
    "                flag = 0\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
